# 语言解析器思路分析（Go 实现，使用 `{}` 块）

本文给出一个“像 Python 一样易读、但允许使用 `{}` 表示代码块”的语言解析器落地方案：先完成 **Lexer → Parser → AST**，确保语法可迭代、错误可读、测试可回归；运行时/类型系统后置。

---

## 约束与定位

- **实现语言**：Go
- **块结构**：使用 `{}`（不做 Python 的缩进 INDENT/DEDENT）
- **阶段目标**：先做“解析器”（把源码解析成 AST + 位置 Span + 错误恢复）
- **风格参考**：表达式/语句风格接近 Python（比如 `if/else/elif`、`def`、`return`、`and/or/not`），但语法细节可做取舍。

---

## 一句话目标（可验证）

给定一份源码文件，解析器能输出：

- **稳定的 AST**（可序列化用于 golden test）
- **准确的错误位置**（行列 + 相关 token）
- **可继续解析**（遇到错误不会直接崩溃，尽量产出后续顶层节点）

---

## 范围建议（先做什么 / 暂不做什么）

### 先做（MVP 语法集合）

- **字面量**：`int/float/string/bool/null`
- **表达式**：
  - 一元：`-x`、`not x`
  - 二元：算术、比较、逻辑（`and/or`）
  - 调用：`f(a, b)`
  - 属性：`a.b`
  - 索引：`a[i]`
  - 分组：`(expr)`
- **语句**：
  - 表达式语句：`foo()`、`a.b`
  - 赋值：`x = expr`
  - `return expr?`、`break`、`continue`
  - `if/elif/else`、`while`
  - `def name(params) { ... }`

### 暂缓（容易拖慢主线）

- 推导式、装饰器、`async/await`、模式匹配、`with`
- 类/继承（可后置）
- 类型注解/静态类型（可后置）
- import 系统（可先做“字符串模块名 + 文件加载”再完善）

---

## 技术路线：手写 Lexer + 递归下降语句 + Pratt 表达式

### 为什么这么选

- **语法在变化期**：手写解析器改动成本低、调试直观
- **表达式复杂**：Pratt（或 precedence climbing）对运算符优先级/结合性非常友好
- **错误体验**：手写更容易做“精准报错 + 恢复同步点”

> 备选：若你更想“写语法文件”，可考虑 ANTLR（缩进不是问题了，因为用 `{}`），但 Go 侧工程/生成物管理要提前规范化。

---

## 建议目录结构（可直接照搬）

建议从解析器开始把边界分清，避免后续运行时混进 parser：

```
internal/
  token/        // Token 类型、种类枚举、关键字表
  span/         // Position/Span（行、列、offset）
  lexer/        // 词法分析：源码 -> tokens
  ast/          // 语法 AST 节点定义（只做语法层）
  parser/       // 语法分析：tokens -> AST + diagnostics
  diag/         // 诊断信息：error/warn，带 Span、message、hint
cmd/
  light/        // CLI：light parse <file> 输出 AST 或错误
docs/
  语言解析器思路分析.md
```

---

## 词法（Lexer）设计

### 核心输出

- `Token{Kind, Lexeme, Span}`，其中：
  - `Kind`：枚举（IDENT、INT、STRING、IF…、PLUS…）
  - `Lexeme`：原始文本（便于错误展示；也可按需只存 offset 范围）
  - `Span`：`{StartPos, EndPos}`（行、列、offset）

### 关键字与操作符建议

- **关键字**（起步够用）：`if/elif/else/while/def/return/break/continue/true/false/null/and/or/not`
- **分隔符**：`(`/`)`、`{`/`}`、`[`/`]`、`,`、`.`、`:`（可选）、`;`（可选）
- **操作符**：
  - 赋值：`=`
  - 比较：`== != < <= > >=`
  - 算术：`+ - * / %`

### 换行（语句分隔）的处理（推荐策略）

既然使用 `{}`，你可以把语句分隔简化为两种任选其一：

- **方案 A（更像 Python）**：换行是语句分隔符；Lexer 产出 `NEWLINE`，Parser 在“顶层/块内”把 `NEWLINE` 当分隔符（并允许连续空行）。
  - 需要处理：括号/方括号/花括号内部的“软换行”（通常不产 `NEWLINE`，或 parser 忽略）
- **方案 B（更像 C/Go）**：用 `;` 分隔语句；换行只用于定位，不参与语法。

若你的目标是“像 Python”，建议 **方案 A**，但实现时仍然可以允许用户显式写 `;`（用于一行多语句，或 REPL）。

---

## 语法（Parser）总体结构

### 两层解析

- **语句/声明**：递归下降（清晰、可控）
- **表达式**：Pratt（处理优先级与结合性）

### 顶层入口

- `parseFile()`：反复解析 `stmtOrDecl` 直到 `EOF`
- 为了错误恢复：在失败时前进 token，并跳到同步点（详见“错误恢复”）

---

## 语法草案（EBNF，MVP）

> 这是“第一版可运行”的语法骨架，后续可以非常容易扩展。

```
file        = { sep }, { toplevel, { sep } }, EOF ;
sep         = NEWLINE | ";" ;

toplevel    = funcDecl | stmt ;

funcDecl    = "def", IDENT, "(", [ paramList ], ")", block ;
paramList   = IDENT, { ",", IDENT } ;

block       = "{", { sep }, { stmt, { sep } }, "}" ;

stmt        = ifStmt
            | whileStmt
            | returnStmt
            | breakStmt
            | continueStmt
            | simpleStmt ;

ifStmt      = "if", expr, block, { "elif", expr, block }, [ "else", block ] ;
whileStmt   = "while", expr, block ;

returnStmt  = "return", [ expr ] ;
breakStmt   = "break" ;
continueStmt= "continue" ;

simpleStmt  = assignStmt | exprStmt ;
assignStmt  = lvalue, "=", expr ;
exprStmt    = expr ;

lvalue      = IDENT, { ".", IDENT | "[", expr, "]" } ;
```

说明：

- `sep` 允许 `NEWLINE` 或 `;`，这样既“像 Python”，也给未来 REPL/格式化留空间。
- `lvalue` 先限制为“标识符/属性/索引”的组合；不要一开始就支持解构赋值，避免复杂度暴增。

---

## 表达式解析（Pratt / precedence climbing）

### 运算符优先级表（示例）

从低到高（可按你想要的 Python 风格微调）：

1. `or`
2. `and`
3. 比较：`== != < <= > >=`
4. `+ -`
5. `* / %`
6. 前缀：`not -`
7. 后缀（最高）：调用 `()`、索引 `[]`、属性 `.`

### Pratt 关键点

- `parseExpr(minBP)`：
  - 先解析前缀（nud）：字面量、IDENT、`(` expr `)`、前缀运算符
  - 再循环处理后缀/中缀（led）：根据当前 token 的 binding power 判断是否继续
- 后缀（call/index/member）通常是“非常高的优先级”，并且是左结合链式解析：`a.b(c)[i].d`

> 经验：把“后缀链”写成一个小循环（解析完 primary 后不断吃 `(` / `[` / `.`）也很清晰。

---

## AST 设计建议（语法 AST）

### 必要字段：Span

每个节点都带 `Span`（起止位置），并且尽量让 Span 覆盖“完整语法片段”：

- 二元表达式：从左操作数开始，到右操作数结束
- `if` 语句：覆盖 `if` 到最后一个 block 的 `}`

### 节点分层

建议至少分三类接口（或结构体 embedding）：

- `Expr`：表达式节点
- `Stmt`：语句节点
- `Decl`：声明节点（如函数）

起步常见节点：

- Expr：`IdentExpr`、`LiteralExpr`、`UnaryExpr`、`BinaryExpr`、`CallExpr`、`IndexExpr`、`MemberExpr`
- Stmt：`ExprStmt`、`AssignStmt`、`ReturnStmt`、`IfStmt`、`WhileStmt`、`BlockStmt`
- Decl：`FuncDecl`

> 语义（名字绑定、作用域、常量折叠等）建议不要塞进 AST；另做 `internal/sem/`，并产生语义 IR 或在 AST 上挂 symbol 信息（两者择一）。

---

## 错误处理与恢复（让解析器“可用”的关键）

### 诊断信息（Diagnostics）

每条错误建议包含：

- `Span`：出错位置
- `Message`：简洁原因（“期望 `)`，但遇到了 `}`”）
- `Hint`：可选提示（“检查是否缺少右括号”）
- `Notes`：可选上下文（例如“在这里开始了一个参数列表”）

### 恢复策略（同步点）

解析失败时不要死循环，通常做：

- 前进 token，直到遇到同步点，再继续

推荐同步点：

- 语句层：`NEWLINE`、`;`、`}`、`EOF`
- 声明层（如 `def` 失败）：也可同步到 `NEWLINE`/`}`/`EOF`

> 经验：先实现“语句级恢复”就能显著提升体验；表达式内部恢复可后置（先报一个错并跳到下一个同步点即可）。

---

## 测试策略（强烈建议从第一天就做）

### Golden tests（最重要）

- 输入：源码片段（或文件）
- 输出：AST 的稳定文本表示（比如 S-expression/JSON/自定义 pretty print）
- 断言：输出与期望完全一致

建议 AST pretty print **不要依赖 map iteration**（Go map 无序会导致不稳定）。

### 负例测试（错误用例）

- 缺括号、缺 `}`、未知 token、错误关键字位置
- 断言：错误数量、错误 message、错误 span 大致准确；并且 parser 不崩溃、能继续产出后续顶层节点

### 语法演进回归

每次添加语法，都补：

- 1~3 个正例（可解析并 AST 正确）
- 1 个负例（典型错误提示）

---

## CLI（把解析器“用起来”）

建议提供一个最小命令行：

- `light parse <file> --ast`：输出 AST
- `light parse <file> --tokens`：输出 token（排查 lexer/parser 问题非常高效）
- 失败时：输出诊断列表（含行列、指示符、附近上下文行）

这样你能快速闭环：改语法 → 运行 parse → 看 AST/报错 → 补测试。

---

## 里程碑（建议按周/按迭代）

### Milestone 0：骨架（1-2 天）

- Token/Span/Diag 结构定义
- Lexer 支持：标识符、数字、字符串、关键字、操作符、分隔符、注释、NEWLINE（若采用方案 A）
- CLI：`--tokens`

### Milestone 1：表达式（2-4 天）

- primary（字面量/ident/分组）
- 后缀链（call/index/member）
- 一元/二元 + 优先级
- golden tests 覆盖 30+ 个表达式样例

### Milestone 2：语句与块（3-6 天）

- `{}` block
- 赋值、return、if/elif/else、while
- CLI：`--ast`
- 错误恢复同步点（stmt 级别）

### Milestone 3：函数（2-4 天）

- `def` + 参数列表 + `return`
- 解析错误恢复：函数体缺 `}`、参数缺 `)` 等

到此为止，你就拥有一个“可演进”的前端：能稳定产出 AST、支撑后续解释器/编译器。

---

## 后续扩展建议（按收益排序）

- **名字绑定/作用域**：函数参数、局部变量、块作用域策略（Python 风格 vs C 风格需决策）
- **解释器**：基于 AST 直接解释（最简单的运行时）
- **字节码**：当解释器性能/可控性成为问题时再引入
- **模块/导入**：先做最小可用（按文件路径或模块名定位）
- **格式化与 LSP**：当 AST/Span 稳定后再做工具链（tree-sitter 可作为编辑器解析补充，但不是必须）

---

## 关键设计决策清单（建议尽早定下来）

- 语句分隔：只用 `;` 还是 `NEWLINE` + 可选 `;`
- 块作用域：`{}` 是否引入新作用域（影响后续语义/运行时）
- `elif` 是关键字还是 `else if` 的语法糖
- 比较是否允许链式（Python 的 `a < b < c`）——建议先不做
- 赋值是否允许作为表达式（建议先不允许，避免歧义）

---

## 参考实现方式（Go 侧工程建议）

- 解析器内部：尽量使用小结构体 + 方法，不要过早引入泛型/复杂抽象
- 所有公用结构：`token` / `span` / `diag` 独立包，避免循环依赖
- AST pretty printer：写成独立模块，测试时直接比对文本

---

如果你愿意，我也可以在当前仓库里把上述目录骨架、Token/Span/Diag、一个最小 Lexer、以及 `light parse --tokens/--ast` 的 CLI 起一个可运行的初版（配上少量 golden tests），让你立刻能开始迭代语法。

