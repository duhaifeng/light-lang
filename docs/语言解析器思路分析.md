# 语言解析器思路分析（Go 实现，使用 `{}` 块）

本文给出一个“语法更像 TS/Java、但仍保持实现简洁”的语言解析器落地方案：先完成 **Lexer → Parser → AST**，确保语法可迭代、错误可读、测试可回归；运行时/类型系统后置。

---

## 约束与定位

- **实现语言**：Go
- **块结构**：使用 `{}`（不做 Python 的缩进 INDENT/DEDENT）
- **阶段目标**：先做“解析器”（把源码解析成 AST + 位置 Span + 错误恢复）
- **风格参考**：语法尽量贴近 TS/Java（比如 `if (cond) {}`、`else if`、`function`、`var/const`、`class/new/constructor` 等），并以工具链友好（LSP/format/lint）为导向。

---

## 一句话目标（可验证）

给定一份源码文件，解析器能输出：

- **稳定的 AST**（可序列化用于 golden test）
- **准确的错误位置**（行列 + 相关 token）
- **可继续解析**（遇到错误不会直接崩溃，尽量产出后续顶层节点）

---

## 范围建议（先做什么 / 暂不做什么）

### 先做（MVP 语法集合）

- **字面量**：`int/float/string/bool/null`
- **表达式**：
  - 一元：`-x`、`!x`
  - 二元：算术、比较、逻辑（`&&/||`）
  - 调用：`f(a, b)`
  - 属性：`a.b`
  - 索引：`a[i]`
  - 分组：`(expr)`
- **语句**：
  - 表达式语句：`foo()`、`a.b`
  - 赋值：`x = expr`
  - `return expr?`、`break`、`continue`
  - `if/else if/else`、`while`
  - `function name(params) { ... }`
  - `var/const name = expr`（变量声明）
  - `class Name { constructor(...) { ... } method(...) { ... } }`（可先做“只含方法”的最小类体）

### 暂缓（容易拖慢主线）

- 推导式、装饰器、`async/await`、模式匹配、`with`
- 继承/接口/访问控制（`extends`/`implements`/`public`/`private` 等，可后置）
- 类型注解/静态类型（可后置）
- import 系统（可先做“字符串模块名 + 文件加载”再完善）

---

## 技术路线：手写 Lexer + 递归下降语句 + Pratt 表达式

### 为什么这么选

- **语法在变化期**：手写解析器改动成本低、调试直观
- **表达式复杂**：Pratt（或 precedence climbing）对运算符优先级/结合性非常友好
- **错误体验**：手写更容易做“精准报错 + 恢复同步点”

> 备选：若你更想“写语法文件”，可考虑 ANTLR（缩进不是问题了，因为用 `{}`），但 Go 侧工程/生成物管理要提前规范化。

---

## 建议目录结构（可直接照搬）

建议从解析器开始把边界分清，避免后续运行时混进 parser：

```
internal/
  token/        // Token 类型、种类枚举、关键字表
  span/         // Position/Span（行、列、offset）
  lexer/        // 词法分析：源码 -> tokens
  ast/          // 语法 AST 节点定义（只做语法层）
  parser/       // 语法分析：tokens -> AST + diagnostics
  diag/         // 诊断信息：error/warn，带 Span、message、hint
cmd/
  light/        // CLI：light parse <file> 输出 AST 或错误
docs/
  语言解析器思路分析.md
```

---

## 词法（Lexer）设计

### 核心输出

- `Token{Kind, Lexeme, Span}`，其中：
  - `Kind`：枚举（IDENT、INT、STRING、IF…、PLUS…）
  - `Lexeme`：原始文本（便于错误展示；也可按需只存 offset 范围）
  - `Span`：`{StartPos, EndPos}`（行、列、offset）

### 关键字与操作符建议

- **关键字**（起步够用）：`if/else/while/function/return/break/continue/var/const/class/new/constructor/this/true/false/null`
- **分隔符**：`(`/`)`、`{`/`}`、`[`/`]`、`,`、`.`、`:`（可选）、`;`（可选）
- **操作符**：
  - 赋值：`=`
  - 比较：`== != < <= > >=`
  - 算术：`+ - * / %`
  - 逻辑：`&& || !`

### 换行（语句分隔）的处理（推荐策略）

既然使用 `{}`，你可以把语句分隔简化为两种任选其一：

- **方案 A（更像“无分号风格”）**：换行是语句分隔符；Lexer 产出 `NEWLINE`，Parser 在“顶层/块内”把 `NEWLINE` 当分隔符（并允许连续空行）。
  - 需要处理：括号/方括号/花括号内部的“软换行”（通常不产 `NEWLINE`，或 parser 忽略）
- **方案 B（更像 TS/Java）**：用 `;` 分隔语句；换行只用于定位，不参与语法。

若你的目标是“像 TS/Java”，建议 **方案 B** 或 “B 为主 + 允许换行当分隔符”（降低写示例/REPL 的心智负担）。本文其余示例沿用 `sep = NEWLINE | ";"`，兼容两种写法。

---

## 语法（Parser）总体结构

### 两层解析

- **语句/声明**：递归下降（清晰、可控）
- **表达式**：Pratt（处理优先级与结合性）

### 顶层入口

- `parseFile()`：反复解析 `stmtOrDecl` 直到 `EOF`
- 为了错误恢复：在失败时前进 token，并跳到同步点（详见“错误恢复”）

---

## 语法草案（EBNF，MVP，TS/Java 风格）

> 这是“第一版可运行”的语法骨架，后续可以非常容易扩展。

```
file        = { sep }, { toplevel, { sep } }, EOF ;
sep         = NEWLINE | ";" ;

toplevel    = funcDecl | classDecl | stmt ;

funcDecl    = "function", IDENT, "(", [ paramList ], ")", block ;
paramList   = IDENT, { ",", IDENT } ;

block       = "{", { sep }, { stmt, { sep } }, "}" ;

stmt        = ifStmt
            | whileStmt
            | returnStmt
            | breakStmt
            | continueStmt
            | varDecl
            | simpleStmt ;

ifStmt      = "if", "(", expr, ")", block,
              { "else", "if", "(", expr, ")", block },
              [ "else", block ] ;
whileStmt   = "while", "(", expr, ")", block ;

returnStmt  = "return", [ expr ] ;
breakStmt   = "break" ;
continueStmt= "continue" ;

varDecl     = ("var" | "const"), IDENT, [ "=", expr ] ;

simpleStmt  = assignStmt | exprStmt ;
assignStmt  = lvalue, "=", expr ;
exprStmt    = expr ;

lvalue      = IDENT, { ".", IDENT | "[", expr, "]" } ;

classDecl   = "class", IDENT, classBody ;
classBody   = "{", { classMember, { sep } }, "}" ;
classMember = constructorDecl | methodDecl ;
constructorDecl = "constructor", "(", [ paramList ], ")", block ;
methodDecl  = IDENT, "(", [ paramList ], ")", block ;
```

说明：

- `sep` 允许 `NEWLINE` 或 `;`，这样既兼容“无分号风格”，也更贴近 TS/Java，并给未来 REPL/格式化留空间。
- `lvalue` 先限制为“标识符/属性/索引”的组合；不要一开始就支持解构赋值，避免复杂度暴增。
- `classBody` 先只支持方法/构造器（不做字段声明语法也没问题：字段可通过 `this.x = ...` 动态出现，语义/运行时阶段再决定是否允许）。

---

## 表达式解析（Pratt / precedence climbing）

### 运算符优先级表（示例）

从低到高（可按你想要的 TS/Java 风格微调）：

1. `||`
2. `&&`
3. 比较：`== != < <= > >=`
4. `+ -`
5. `* / %`
6. 前缀：`! -`
7. 后缀（最高）：调用 `()`、索引 `[]`、属性 `.`

### Pratt 关键点

- `parseExpr(minBP)`：
  - 先解析前缀（nud）：字面量、IDENT、`(` expr `)`、前缀运算符
  - 再循环处理后缀/中缀（led）：根据当前 token 的 binding power 判断是否继续
- 后缀（call/index/member）通常是“非常高的优先级”，并且是左结合链式解析：`a.b(c)[i].d`

> 经验：把“后缀链”写成一个小循环（解析完 primary 后不断吃 `(` / `[` / `.`）也很清晰。

---

## AST 设计建议（语法 AST）

### 必要字段：Span

每个节点都带 `Span`（起止位置），并且尽量让 Span 覆盖“完整语法片段”：

- 二元表达式：从左操作数开始，到右操作数结束
- `if` 语句：覆盖 `if` 到最后一个 block 的 `}`

### 节点分层

建议至少分三类接口（或结构体 embedding）：

- `Expr`：表达式节点
- `Stmt`：语句节点
- `Decl`：声明节点（如函数）

起步常见节点：

- Expr：`IdentExpr`、`LiteralExpr`、`UnaryExpr`、`BinaryExpr`、`CallExpr`、`IndexExpr`、`MemberExpr`
- Stmt：`ExprStmt`、`AssignStmt`、`ReturnStmt`、`IfStmt`、`WhileStmt`、`BlockStmt`
- Decl：`FuncDecl`

> 语义（名字绑定、作用域、常量折叠等）建议不要塞进 AST；另做 `internal/sem/`，并产生语义 IR 或在 AST 上挂 symbol 信息（两者择一）。

---

## 错误处理与恢复（让解析器“可用”的关键）

### 诊断信息（Diagnostics）

每条错误建议包含：

- `Span`：出错位置
- `Message`：简洁原因（“期望 `)`，但遇到了 `}`”）
- `Hint`：可选提示（“检查是否缺少右括号”）
- `Notes`：可选上下文（例如“在这里开始了一个参数列表”）

### 恢复策略（同步点）

解析失败时不要死循环，通常做：

- 前进 token，直到遇到同步点，再继续

推荐同步点：

- 语句层：`NEWLINE`、`;`、`}`、`EOF`
- 声明层（如 `function`/`class` 失败）：也可同步到 `NEWLINE`/`}`/`EOF`

> 经验：先实现“语句级恢复”就能显著提升体验；表达式内部恢复可后置（先报一个错并跳到下一个同步点即可）。

---

## 测试策略（强烈建议从第一天就做）

### Golden tests（最重要）

- 输入：源码片段（或文件）
- 输出：AST 的稳定文本表示（比如 S-expression/JSON/自定义 pretty print）
- 断言：输出与期望完全一致

建议 AST pretty print **不要依赖 map iteration**（Go map 无序会导致不稳定）。

### 负例测试（错误用例）

- 缺括号、缺 `}`、未知 token、错误关键字位置
- 断言：错误数量、错误 message、错误 span 大致准确；并且 parser 不崩溃、能继续产出后续顶层节点

### 语法演进回归

每次添加语法，都补：

- 1~3 个正例（可解析并 AST 正确）
- 1 个负例（典型错误提示）

---

## CLI（把解析器“用起来”）

建议提供一个最小命令行：

- `light parse <file> --ast`：输出 AST
- `light parse <file> --tokens`：输出 token（排查 lexer/parser 问题非常高效）
- 失败时：输出诊断列表（含行列、指示符、附近上下文行）

这样你能快速闭环：改语法 → 运行 parse → 看 AST/报错 → 补测试。

---

## 里程碑（建议按周/按迭代）

### Milestone 0：骨架（1-2 天）

- Token/Span/Diag 结构定义
- Lexer 支持：标识符、数字、字符串、关键字、操作符、分隔符、注释、NEWLINE（若采用方案 A）
- CLI：`--tokens`

### Milestone 1：表达式（2-4 天）

- primary（字面量/ident/分组）
- 后缀链（call/index/member）
- 一元/二元 + 优先级
- golden tests 覆盖 30+ 个表达式样例

### Milestone 2：语句与块（3-6 天）

- `{}` block
- 赋值、return、if/else if/else、while、var/const
- CLI：`--ast`
- 错误恢复同步点（stmt 级别）

### Milestone 3：函数（2-4 天）

- `function` + 参数列表 + `return`
- 解析错误恢复：函数体缺 `}`、参数缺 `)` 等

到此为止，你就拥有一个“可演进”的前端：能稳定产出 AST、支撑后续解释器/编译器。

---

## 后续扩展建议（按收益排序）

 - **名字绑定/作用域**：函数参数、局部变量、块作用域策略（`var/const` 是否引入块作用域、是否需要 hoist，这类语义需要尽早定）
- **解释器**：基于 AST 直接解释（最简单的运行时）
- **字节码**：当解释器性能/可控性成为问题时再引入
- **模块/导入**：先做最小可用（按文件路径或模块名定位）
- **格式化与 LSP**：当 AST/Span 稳定后再做工具链（tree-sitter 可作为编辑器解析补充，但不是必须）

---

## 跨语言复用建议（你选择 A + C 的落地方案）

你的目标是：

- **A（工具链）**：在 TypeScript/Java 里做 lint/format/IDE 等工具
- **C（调用解析结果）**：TypeScript/Java 不一定要自己实现完整 parser，而是“消费解析输出”

在这种组合下，最推荐的架构是：

- **官方/权威解析器只维护一份（Go）**：Lexer + Parser + AST + Diagnostics
- **对外提供稳定协议（AST + Diagnostics）**：TS/Java 通过协议消费结果
- **编辑器侧增量解析（可选）**：TS 用 tree-sitter 做高亮/折叠/outline；遇到保存、格式化、精确报错时再调用 Go 权威解析器

### 为什么“共享协议/测试”比“共享代码”更重要

当语法仍在演进时，多语言共享同一份解析代码（或生成器）往往会引入工具链/版本耦合；而共享以下内容更稳：

- **语法规范**：EBNF + 运算符优先级表 + Token/关键字表
- **协议规范**：AST/Diagnostics 的结构与版本号
- **golden tests**：`源码 -> AST(JSON)` 与 `源码 -> diagnostics(JSON)`

这样 TS/Java 工具链只要跟着协议升级即可，不必承担“实现一份 parser”的持续维护成本。

### 两种消费形态（建议先 CLI，后服务）

#### 形态 1：本地 CLI（推荐起步，最简单）

提供命令：

- `light parse <file> --format=json` 输出 `{ ast, diagnostics }`
- 可选：`light parse <file> --tokens --format=json` 辅助调试

TS/Java 侧通过 `spawn process` 调用并解析 JSON。适用场景：

- 格式化器（format）
- lint（离线/CI）
- 简单索引/分析工具

#### 形态 2：HTTP/gRPC 服务（高频/批量/LSP 场景）

提供接口：

- `POST /parse`（或 gRPC `Parse`），入参 `{sourceId, text}`，出参 `{ast, diagnostics}`

适用场景：

- 语言服务器（LSP）
- 批量工程索引（一次解析很多文件）
- 需要缓存/并发/增量策略的工具链

> 一般建议：先做 CLI 把协议跑通；当工具链调用频率变高、启动开销成为问题时再加服务层。

### 协议设计要点（确保 TS/Java 好用且长期稳定）

#### Span（强烈建议用 offset/length 为主）

跨语言最稳定的定位方式是使用字符偏移：

- `span: { start: <offset>, end: <offset> }` 或 `{ offset, length }`
- 行列（line/column）可以作为“展示字段”，但不要作为唯一真相（不同换行/编码处理容易漂移）

#### AST 结构（建议 tagged-union JSON）

每个节点统一：

- `kind`: `"IfStmt" | "BinaryExpr" | ...`
- `span`: `{...}`
- 其他字段按节点类型定义（子节点、token 值、操作符枚举等）

并在根对象携带：

- `astVersion`：AST 结构版本号（语法演进时最关键）
- `sourceId`：文件名或逻辑 ID（便于缓存与诊断归属）

#### Diagnostics（建议带 error code，便于测试与本地化）

每条诊断建议包含：

- `code`: `"E0001"`（稳定错误码）
- `severity`: `"error" | "warning"`
- `message`: 简洁描述
- `span`: `{...}`
- 可选 `hint/notes`

这样 TS/Java 可以：

- 用 `code` 做稳定断言（不依赖 message 文本）
- message 未来可本地化

### TS 工具链的“体验最佳组合”

- **tree-sitter（TS 侧）**：用于高亮、折叠、outline、结构选择（增量、快速、适合编辑器）
- **Go 权威解析器**：用于保存/格式化/lint/精确错误（保证语法一致性）

典型策略：

- 编辑中：tree-sitter 常驻
- 保存或显式触发：调用 `light parse --json` 获取权威 AST/diagnostics

### Java 工具链建议

Java 侧若主要做：

- lint/format/索引：直接调用 Go CLI/服务并基于 AST 工作
- 若未来确实需要在 JVM 内嵌运行且不能依赖外部进程/服务，再考虑“Java 实现一份 parser”或引入生成器（但这通常是后期需求）

---

## Go vs TypeScript：实现语言怎么选（补充结论）

你同时会 Go 和 TypeScript 时，可以按“你最在乎的目标”来选：

- **更偏工程/性能/权威性（推荐 Go）**：
  - 适合做“单一权威解析器”，输出稳定协议（AST + Diagnostics）
  - 产物易分发：一个 CLI 二进制即可覆盖本地开发、CI、服务化
  - 大工程/多文件解析与并发索引更稳
- **更偏工具链/前端生态/迭代速度（推荐 TypeScript）**：
  - 适合做 Web/IDE 侧工具（VSCode 插件、playground、可视化 AST）
  - 生态衔接自然：tree-sitter、LSP、编辑器集成与增量体验更顺

### 针对你当前的目标（A + C）的推荐组合

你的组合是：

- **A（工具链）**：TypeScript/Java 要做 lint/format/IDE
- **C（消费解析结果）**：TS/Java 希望主要“调用解析输出”

因此更推荐：

- **Go 做权威解析器**（官方前端：Lexer/Parser/AST/Diagnostics，提供 CLI/服务输出协议）
- **TypeScript 做工具链体验层**（tree-sitter 用于编辑器增量解析；保存/format/lint 时调用 Go 权威解析器拿准确 AST/诊断）

### 什么时候更适合 TypeScript 做权威解析器

- 你明确要把解析器直接跑在 **浏览器端**（离线、无本地二进制、也不依赖服务）
- 解析规模不大，性能压力低于“工程化分发/跨平台一致性”的优先级
- 团队贡献者主要在 JS/TS 生态，希望统一技术栈

---

## 关键设计决策清单（建议尽早定下来）

- 语句分隔：只用 `;` 还是 `NEWLINE` + 可选 `;`
- 条件括号：`if/while` 是否强制写成 `if (expr)` / `while (expr)`（更 TS/Java 友好）
- 变量声明：是否要求首次赋值必须使用 `var/const`（更易做静态分析与 lint）
- 块作用域：`{}` 是否引入新作用域（影响后续语义/运行时）
- `else if`：是否只支持 `else if`（不再引入 `elif` 关键字）
- 面向对象：是否支持字段声明语法（`x: int` 或 `x = 1` 这类），以及是否引入 `extends/implements/public/private`
- 比较是否允许链式（Python 的 `a < b < c`）——建议先不做
- 赋值是否允许作为表达式（建议先不允许，避免歧义）

---

## 参考实现方式（Go 侧工程建议）

- 解析器内部：尽量使用小结构体 + 方法，不要过早引入泛型/复杂抽象
- 所有公用结构：`token` / `span` / `diag` 独立包，避免循环依赖
- AST pretty printer：写成独立模块，测试时直接比对文本

---

如果你愿意，我也可以在当前仓库里把上述目录骨架、Token/Span/Diag、一个最小 Lexer、以及 `light parse --tokens/--ast` 的 CLI 起一个可运行的初版（配上少量 golden tests），让你立刻能开始迭代语法。

